{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from process_dataset import speech_features, text_features\n",
    "import numpy as np\n",
    "\n",
    "from ensemble import StackEnsemble, VoteEnsemble, BlendEnsemble\n",
    "\n",
    "from speech_models import speech_logistic_regression, speech_mlp, speech_naive_bayes, speech_random_forest, speech_svm, speech_xgboost\n",
    "from text_models import text_logistic_regression, text_mlp, text_naive_bayes, text_random_forest, text_svm, text_xgboost\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_models():\n",
    "\n",
    "    models = list()\n",
    "\n",
    "    models.append(('Support Vector Machine', speech_svm.get_svm()))\n",
    "    # models.append(('Random Forest Classifier', speech_random_forest.get_random_forest()))\n",
    "    # models.append(('Multinomial Naive Bayes', speech_naive_bayes.get_naive_bayes()))\n",
    "    models.append(('Logistic Regression', speech_logistic_regression.get_logistic_regression()))\n",
    "    # models.append(('MLP Classifier', speech_mlp.get_mlp()))\n",
    "    models.append(('XGBoost', speech_xgboost.get_xgb()))\n",
    "\n",
    "    return models\n",
    "\n",
    "def get_text_models():\n",
    "    \n",
    "    models = list()\n",
    "\n",
    "    models.append(('Support Vector Machine', text_svm.get_svm()))\n",
    "    models.append(('Random Forest Classifier', text_random_forest.get_random_forest()))\n",
    "    # models.append(('Multinomial Naive Bayes', text_naive_bayes.get_naive_bayes()))\n",
    "    models.append(('Logistic Regression', text_logistic_regression.get_logistic_regression()))\n",
    "    models.append(('MLP Classifier', text_mlp.get_mlp()))\n",
    "    # models.append(('XGBoost', text_xgboost.get_xgb()))\n",
    "\n",
    "    return models\n",
    "\n",
    "def print_scores(scores):\n",
    "    print('Accuracy: ', np.mean(scores['test_accuracy']))\n",
    "    print('F1 Macro: ', np.mean(scores['test_f1_macro']))\n",
    "    print('Precision Macro: ', np.mean(scores['test_precision_macro']))\n",
    "    print('Recall Macro: ', np.mean(scores['test_recall_macro']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s, x_test_s, y_train_s, y_test_s = speech_features.get_train_test()\n",
    "x_train_t, x_test_t, y_train_t, y_test_t = text_features.get_train_test()\n",
    "speech_x_y = speech_features.get_data()\n",
    "text_x_y = text_features.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vote Ensemble (Soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter = VoteEnsemble(get_speech_models(), get_text_models(), type='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8777    0.7933    0.8333       208\n",
      "         hap     0.8205    0.8076    0.8140       317\n",
      "         neu     0.7587    0.7669    0.7628       369\n",
      "         sad     0.7564    0.8310    0.7919       213\n",
      "\n",
      "    accuracy                         0.7958      1107\n",
      "   macro avg     0.8033    0.7997    0.8005      1107\n",
      "weighted avg     0.7983    0.7958    0.7963      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voter_result = voter.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, voter_result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter.save('soft_voter.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_k_fold = voter.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(voter_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vote Ensemble (Hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter2 = VoteEnsemble(get_speech_models(), get_text_models(), type='hard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter2.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8424    0.7452    0.7908       208\n",
      "         hap     0.7492    0.7445    0.7468       317\n",
      "         neu     0.6888    0.7317    0.7096       369\n",
      "         sad     0.7222    0.7324    0.7273       213\n",
      "\n",
      "    accuracy                         0.7380      1107\n",
      "   macro avg     0.7506    0.7384    0.7436      1107\n",
      "weighted avg     0.7414    0.7380    0.7389      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voter_result2 = voter2.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, voter_result2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter2.save('hard_voter.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_k_fold2 = voter2.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(voter_k_fold2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blend Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cls = LogisticRegression(solver='liblinear', random_state=42)\n",
    "blender = BlendEnsemble(get_speech_models(), get_text_models(), meta_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8143    0.8221    0.8182       208\n",
      "         hap     0.7829    0.8076    0.7950       317\n",
      "         neu     0.7957    0.7073    0.7489       369\n",
      "         sad     0.7479    0.8498    0.7956       213\n",
      "\n",
      "    accuracy                         0.7850      1107\n",
      "   macro avg     0.7852    0.7967    0.7894      1107\n",
      "weighted avg     0.7863    0.7850    0.7841      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blender_result = blender.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, blender_result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender.save('blender.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender_k_fold = blender.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(blender_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cls2 = LogisticRegression(solver='liblinear', random_state=42, n_jobs=-1)\n",
    "stacker = StackEnsemble(get_speech_models(), get_text_models(), meta_cls2, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stacker.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8227    0.8702    0.8458       208\n",
      "         hap     0.8275    0.8170    0.8222       317\n",
      "         neu     0.7946    0.7127    0.7514       369\n",
      "         sad     0.7531    0.8592    0.8026       213\n",
      "\n",
      "    accuracy                         0.8004      1107\n",
      "   macro avg     0.7995    0.8148    0.8055      1107\n",
      "weighted avg     0.8013    0.8004    0.7993      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacker_result = stacker.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, stacker_result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker.save('stacker.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker_k_fold = stacker.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(stacker_k_fold)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ed4bbf83b94bed540e4a6248a5de1e2eb8a809c16f0f6392d7883b316929957"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
