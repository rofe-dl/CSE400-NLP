{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from process_dataset import speech_features, text_features\n",
    "import numpy as np\n",
    "\n",
    "from ensemble import StackEnsemble, VoteEnsemble, BlendEnsemble\n",
    "\n",
    "from speech_models import speech_logistic_regression, speech_mlp, speech_naive_bayes, speech_random_forest, speech_svm, speech_xgboost\n",
    "from text_models import text_logistic_regression, text_mlp, text_naive_bayes, text_random_forest, text_svm, text_xgboost\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_models():\n",
    "\n",
    "    models = list()\n",
    "\n",
    "    models.append(('Support Vector Machine', speech_svm.get_svm()))\n",
    "    # models.append(('Random Forest Classifier', speech_random_forest.get_random_forest()))\n",
    "    # models.append(('Multinomial Naive Bayes', speech_naive_bayes.get_naive_bayes()))\n",
    "    models.append(('Logistic Regression', speech_logistic_regression.get_logistic_regression()))\n",
    "    models.append(('MLP Classifier', speech_mlp.get_mlp()))\n",
    "    models.append(('XGBoost', speech_xgboost.get_xgb()))\n",
    "\n",
    "    return models\n",
    "\n",
    "def get_text_models():\n",
    "    \n",
    "    models = list()\n",
    "\n",
    "    models.append(('Support Vector Machine', text_svm.get_svm()))\n",
    "    models.append(('Random Forest Classifier', text_random_forest.get_random_forest()))\n",
    "    # models.append(('Multinomial Naive Bayes', text_naive_bayes.get_naive_bayes()))\n",
    "    models.append(('Logistic Regression', text_logistic_regression.get_logistic_regression()))\n",
    "    models.append(('MLP Classifier', text_mlp.get_mlp()))\n",
    "    models.append(('XGBoost', text_xgboost.get_xgb()))\n",
    "\n",
    "    return models\n",
    "\n",
    "def print_scores(scores):\n",
    "    print('Accuracy: ', np.mean(scores['test_accuracy']))\n",
    "    print('F1 Macro: ', np.mean(scores['test_f1_macro']))\n",
    "    print('Precision Macro: ', np.mean(scores['test_precision_macro']))\n",
    "    print('Recall Macro: ', np.mean(scores['test_recall_macro']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s, x_test_s, y_train_s, y_test_s = speech_features.get_train_test()\n",
    "x_train_t, x_test_t, y_train_t, y_test_t = text_features.get_train_test()\n",
    "speech_x_y = speech_features.get_data()\n",
    "text_x_y = text_features.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vote Ensemble (Soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter = VoteEnsemble(get_speech_models(), get_text_models(), type='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8950    0.7788    0.8329       208\n",
      "         hap     0.8203    0.7918    0.8058       317\n",
      "         neu     0.7455    0.7859    0.7652       369\n",
      "         sad     0.7619    0.8263    0.7928       213\n",
      "\n",
      "    accuracy                         0.7940      1107\n",
      "   macro avg     0.8057    0.7957    0.7992      1107\n",
      "weighted avg     0.7982    0.7940    0.7948      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voter_result = voter.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, voter_result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter.save('soft_voter.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_k_fold = voter.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(voter_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vote Ensemble (Hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter2 = VoteEnsemble(get_speech_models(), get_text_models(), type='hard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter2.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8508    0.7404    0.7918       208\n",
      "         hap     0.7540    0.7350    0.7444       317\n",
      "         neu     0.6942    0.7507    0.7214       369\n",
      "         sad     0.7248    0.7418    0.7332       213\n",
      "\n",
      "    accuracy                         0.7425      1107\n",
      "   macro avg     0.7560    0.7420    0.7477      1107\n",
      "weighted avg     0.7467    0.7425    0.7435      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voter_result2 = voter2.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, voter_result2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter2.save('hard_voter.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_k_fold2 = voter2.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(voter_k_fold2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blend Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cls = LogisticRegression(solver='liblinear', random_state=42)\n",
    "blender = BlendEnsemble(get_speech_models(), get_text_models(), meta_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Support Vector Machine (Speech) ...\n",
      "Training Logistic Regression (Speech) ...\n",
      "Training MLP Classifier (Speech) ...\n",
      "Training XGBoost (Speech) ...\n",
      "[03:41:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training Support Vector Machine (Text) ...\n",
      "Training Random Forest Classifier (Text) ...\n",
      "Training Logistic Regression (Text) ...\n",
      "Training MLP Classifier (Text) ...\n",
      "Training XGBoost (Text) ...\n",
      "[03:42:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training Meta Classifier ...\n"
     ]
    }
   ],
   "source": [
    "blender.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8095    0.8173    0.8134       208\n",
      "         hap     0.7809    0.7981    0.7894       317\n",
      "         neu     0.7957    0.7073    0.7489       369\n",
      "         sad     0.7388    0.8498    0.7904       213\n",
      "\n",
      "    accuracy                         0.7814      1107\n",
      "   macro avg     0.7812    0.7931    0.7855      1107\n",
      "weighted avg     0.7831    0.7814    0.7806      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blender_result = blender.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, blender_result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender.save('blender.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender_k_fold = blender.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(blender_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cls2 = LogisticRegression(solver='liblinear', random_state=42, n_jobs=-1)\n",
    "stacker = StackEnsemble(get_speech_models(), get_text_models(), meta_cls2, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stacker.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8227    0.8702    0.8458       208\n",
      "         hap     0.8328    0.8013    0.8167       317\n",
      "         neu     0.7851    0.7127    0.7472       369\n",
      "         sad     0.7409    0.8592    0.7957       213\n",
      "\n",
      "    accuracy                         0.7958      1107\n",
      "   macro avg     0.7954    0.8108    0.8013      1107\n",
      "weighted avg     0.7973    0.7958    0.7949      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacker_result = stacker.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, stacker_result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker.save('stacker.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker_k_fold = stacker.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(stacker_k_fold)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ed4bbf83b94bed540e4a6248a5de1e2eb8a809c16f0f6392d7883b316929957"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
