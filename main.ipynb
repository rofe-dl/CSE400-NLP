{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafid/Documents/github/CSE400-NLP/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from speech_models import speech_logistic_regression\n",
    "from process_dataset import speech_features, text_features\n",
    "from ensemble import SpeechTextEnsemble, StackEnsemble, VoteEnsemble, BlendEnsemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, data_type):\n",
    "    if data_type == 'text':\n",
    "        x_train, x_test, y_train, y_test = text_features.get_train_test()\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = speech_features.get_train_test() \n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    results = model.predict(x_test)\n",
    "    return classification_report(y_test, results)\n",
    "\n",
    "def cross_validate(model, data_type, cv=5):\n",
    "    if data_type == 'text':\n",
    "        x, y = text_features.get_data()\n",
    "    else:\n",
    "        x, y = speech_features.get_data()\n",
    "\n",
    "    scoring = {'accuracy': 'accuracy',\n",
    "           'f1_macro': 'f1_macro',\n",
    "           'precision_macro': 'precision_macro',\n",
    "           'recall_macro' : 'recall_macro'}\n",
    "\n",
    "    scores = model.cross_validate(x, y, cv=cv, scoring=scoring)\n",
    "    return scores\n",
    "\n",
    "def print_scores(scores):\n",
    "    print('Accuracy: ', np.mean(scores['test_accuracy']))\n",
    "    print('F1 Macro: ', np.mean(scores['test_f1_macro']))\n",
    "    print('Precision Macro: ', np.mean(scores['test_precision_macro']))\n",
    "    print('Recall Macro: ', np.mean(scores['test_recall_macro']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cls = speech_logistic_regression.get_logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech_model = BlendEnsemble(meta_cls=meta_cls, data_type='speech')\n",
    "speech_model = StackEnsemble(meta_cls=meta_cls, data_type='speech')\n",
    "# speech_model = VoteEnsemble(type='soft', data_type='speech')\n",
    "# speech_model = VoteEnsemble(type='hard', data_type='speech')\n",
    "\n",
    "# speech_report = check_accuracy(speech_model, data_type='speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang       0.80      0.64      0.71       212\n",
      "         hap       0.68      0.69      0.69       333\n",
      "         neu       0.64      0.71      0.68       333\n",
      "         sad       0.73      0.74      0.73       229\n",
      "\n",
      "    accuracy                           0.70      1107\n",
      "   macro avg       0.71      0.70      0.70      1107\n",
      "weighted avg       0.70      0.70      0.70      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(speech_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_k_fold = cross_validate(speech_model, data_type='speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(speech_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_model = BlendEnsemble(meta_cls=meta_cls, data_type='text')\n",
    "text_model = StackEnsemble(meta_cls=meta_cls, data_type='text')\n",
    "# text_model = VoteEnsemble(type='soft', data_type='text')\n",
    "# text_model = VoteEnsemble(type='hard', data_type='text')\n",
    "\n",
    "# text_report = check_accuracy(text_model, data_type='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_k_fold = cross_validate(text_model, data_type='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(text_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech + Text Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = SpeechTextEnsemble(speech_model, text_model, fit_bases=True, type='soft')\n",
    "x_train_s, x_test_s, y_train_s, y_test_s = speech_features.get_train_test()\n",
    "x_train_t, x_test_t, y_train_t, y_test_t = text_features.get_train_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.fit(x_train_s, x_train_t, y_train_s)\n",
    "result = combined_model.predict(x_test_s, x_test_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang       0.82      0.81      0.82       208\n",
      "         hap       0.80      0.77      0.78       317\n",
      "         neu       0.75      0.73      0.74       369\n",
      "         sad       0.75      0.84      0.79       213\n",
      "\n",
      "    accuracy                           0.78      1107\n",
      "   macro avg       0.78      0.79      0.78      1107\n",
      "weighted avg       0.78      0.78      0.78      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_s, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.save('final_model.pkl')\n",
    "text_model.save('stack_text.pkl')\n",
    "speech_model.save('stack_speech.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ed4bbf83b94bed540e4a6248a5de1e2eb8a809c16f0f6392d7883b316929957"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
