{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafid/Documents/github/CSE400-NLP/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from speech_models import speech_logistic_regression\n",
    "from process_dataset import speech_features, text_features\n",
    "from ensemble import SpeechTextEnsemble, StackEnsemble, VoteEnsemble, BlendEnsemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from custom_stack import StackEnsembleCustom\n",
    "from speech_models import speech_logistic_regression, speech_mlp, speech_naive_bayes, speech_random_forest, speech_svm, speech_xgboost\n",
    "from text_models import text_logistic_regression, text_mlp, text_naive_bayes, text_random_forest, text_svm, text_xgboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_models():\n",
    "\n",
    "    models = list()\n",
    "\n",
    "    models.append(('Support Vector Machine', speech_svm.get_svm()))\n",
    "    models.append(('Random Forest Classifier', speech_random_forest.get_random_forest()))\n",
    "    models.append(('Multinomial Naive Bayes', speech_naive_bayes.get_naive_bayes()))\n",
    "    models.append(('Logistic Regression', speech_logistic_regression.get_logistic_regression()))\n",
    "    models.append(('MLP Classifier', speech_mlp.get_mlp()))\n",
    "    models.append(('XGBoost', speech_xgboost.get_xgb()))\n",
    "\n",
    "    # TODO lstm\n",
    "\n",
    "    return models\n",
    "\n",
    "def get_text_models():\n",
    "    \n",
    "    models = list()\n",
    "\n",
    "    models.append(('Support Vector Machine', text_svm.get_svm()))\n",
    "    models.append(('Random Forest Classifier', text_random_forest.get_random_forest()))\n",
    "    models.append(('Multinomial Naive Bayes', text_naive_bayes.get_naive_bayes()))\n",
    "    models.append(('Logistic Regression', text_logistic_regression.get_logistic_regression()))\n",
    "    models.append(('MLP Classifier', text_mlp.get_mlp()))\n",
    "    models.append(('XGBoost', text_xgboost.get_xgb()))\n",
    "\n",
    "    # TODO lstm \n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s, x_test_s, y_train_s, y_test_s = speech_features.get_train_test()\n",
    "x_train_t, x_test_t, y_train_t, y_test_t = text_features.get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:24:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:27:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:30:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:34:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:37:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:40:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:43:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:46:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:49:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:53:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:57:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "meta_cls = LogisticRegression(solver='liblinear', random_state=42)\n",
    "combined_model = StackEnsembleCustom(get_speech_models(), get_text_models(), meta_cls, 5)\n",
    "\n",
    "combined_model.fit(x_train_s, x_train_t.toarray(), y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = combined_model.predict(x_test_s, x_test_t.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8072    0.8654    0.8353       208\n",
      "         hap     0.8006    0.7855    0.7930       317\n",
      "         neu     0.7704    0.6911    0.7286       369\n",
      "         sad     0.7397    0.8404    0.7868       213\n",
      "\n",
      "    accuracy                         0.7796      1107\n",
      "   macro avg     0.7795    0.7956    0.7859      1107\n",
      "weighted avg     0.7801    0.7796    0.7783      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_s, result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"trained_models/stack_custom.pkl\", 'wb') as f:\n",
    "    pickle.dump(combined_model, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ed4bbf83b94bed540e4a6248a5de1e2eb8a809c16f0f6392d7883b316929957"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
