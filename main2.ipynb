{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from process_dataset import speech_features, text_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from ensemble import StackEnsemble, VoteEnsemble, BlendEnsemble\n",
    "\n",
    "from speech_models import speech_logistic_regression, speech_mlp, speech_naive_bayes, speech_random_forest, speech_svm, speech_xgboost\n",
    "from text_models import text_logistic_regression, text_mlp, text_naive_bayes, text_random_forest, text_svm, text_xgboost\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_models():\n",
    "\n",
    "    models = list()\n",
    "\n",
    "    models.append(('Support Vector Machine', speech_svm.get_svm()))\n",
    "    models.append(('Random Forest Classifier', speech_random_forest.get_random_forest()))\n",
    "    models.append(('Multinomial Naive Bayes', speech_naive_bayes.get_naive_bayes()))\n",
    "    models.append(('Logistic Regression', speech_logistic_regression.get_logistic_regression()))\n",
    "    models.append(('MLP Classifier', speech_mlp.get_mlp()))\n",
    "    models.append(('XGBoost', speech_xgboost.get_xgb()))\n",
    "\n",
    "    # TODO lstm\n",
    "\n",
    "    return models\n",
    "\n",
    "def get_text_models():\n",
    "    \n",
    "    models = list()\n",
    "\n",
    "    models.append(('Support Vector Machine', text_svm.get_svm()))\n",
    "    models.append(('Random Forest Classifier', text_random_forest.get_random_forest()))\n",
    "    models.append(('Multinomial Naive Bayes', text_naive_bayes.get_naive_bayes()))\n",
    "    models.append(('Logistic Regression', text_logistic_regression.get_logistic_regression()))\n",
    "    models.append(('MLP Classifier', text_mlp.get_mlp()))\n",
    "    models.append(('XGBoost', text_xgboost.get_xgb()))\n",
    "\n",
    "    # TODO lstm \n",
    "\n",
    "    return models\n",
    "\n",
    "def print_scores(scores):\n",
    "    print('Accuracy: ', np.mean(scores['test_accuracy']))\n",
    "    print('F1 Macro: ', np.mean(scores['test_f1_macro']))\n",
    "    print('Precision Macro: ', np.mean(scores['test_precision_macro']))\n",
    "    print('Recall Macro: ', np.mean(scores['test_recall_macro']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s, x_test_s, y_train_s, y_test_s = speech_features.get_train_test()\n",
    "x_train_t, x_test_t, y_train_t, y_test_t = text_features.get_train_test()\n",
    "speech_x_y = speech_features.get_data()\n",
    "text_x_y = text_features.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vote Ensemble (Soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter = VoteEnsemble(get_speech_models(), get_text_models(), type='soft')\n",
    "voter.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8901    0.7788    0.8308       208\n",
      "         hap     0.7934    0.7634    0.7781       317\n",
      "         neu     0.7381    0.7561    0.7470       369\n",
      "         sad     0.7231    0.8216    0.7692       213\n",
      "\n",
      "    accuracy                         0.7751      1107\n",
      "   macro avg     0.7862    0.7800    0.7813      1107\n",
      "weighted avg     0.7796    0.7751    0.7759      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voter_result = voter.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, voter_result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter.save('soft_voter.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_k_fold = voter.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(voter_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vote Ensemble (Hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter2 = VoteEnsemble(get_speech_models(), get_text_models(), type='hard')\n",
    "voter2.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_result2 = voter2.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, voter_result2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter2.save('hard_voter.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_k_fold2 = voter2.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(voter_k_fold2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blend Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cls = LogisticRegression(solver='liblinear', random_state=42)\n",
    "blender = BlendEnsemble(get_speech_models(), get_text_models(), meta_cls)\n",
    "blender.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8382    0.8221    0.8301       208\n",
      "         hap     0.7830    0.7855    0.7843       317\n",
      "         neu     0.7699    0.7073    0.7373       369\n",
      "         sad     0.7195    0.8310    0.7712       213\n",
      "\n",
      "    accuracy                         0.7751      1107\n",
      "   macro avg     0.7777    0.7865    0.7807      1107\n",
      "weighted avg     0.7768    0.7751    0.7747      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blender_result = blender.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, blender_result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender.save('blender.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender_k_fold = blender.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(blender_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cls2 = LogisticRegression(solver='liblinear', random_state=42)\n",
    "stacker = StackEnsemble(get_speech_models(), get_text_models(), meta_cls2, cv=5, n_jobs=-1)\n",
    "\n",
    "stacker.fit(x_train_s, x_train_t, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8227    0.8702    0.8458       208\n",
      "         hap     0.8058    0.7855    0.7955       317\n",
      "         neu     0.7589    0.6911    0.7234       369\n",
      "         sad     0.7438    0.8451    0.7912       213\n",
      "\n",
      "    accuracy                         0.7814      1107\n",
      "   macro avg     0.7828    0.7980    0.7890      1107\n",
      "weighted avg     0.7814    0.7814    0.7801      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stacker_result = stacker.predict(x_test_s, x_test_t)\n",
    "print(classification_report(y_test_s, stacker_result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker.save('stacker.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker_k_fold = stacker.cross_validate(speech_x_y[0], text_x_y[0], speech_x_y[1], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(stacker_k_fold)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ed4bbf83b94bed540e4a6248a5de1e2eb8a809c16f0f6392d7883b316929957"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
