{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.6567    0.6346    0.6455       208\n",
      "         hap     0.6031    0.6088    0.6060       317\n",
      "         neu     0.6958    0.6260    0.6591       369\n",
      "         sad     0.6378    0.7606    0.6938       213\n",
      "\n",
      "    accuracy                         0.6486      1107\n",
      "   macro avg     0.6484    0.6575    0.6511      1107\n",
      "weighted avg     0.6508    0.6486    0.6480      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "Accuracy:  0.6270055262336831\n",
      "F1 Macro:  0.6322106875281369\n",
      "Precision Macro:  0.6332974290282058\n",
      "Recall Macro:  0.632886589798324\n"
     ]
    }
   ],
   "source": [
    "! python3 -m speech_models.speech_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.6818    0.6490    0.6650       208\n",
      "         hap     0.6355    0.5994    0.6169       317\n",
      "         neu     0.6621    0.6531    0.6576       369\n",
      "         sad     0.6341    0.7324    0.6797       213\n",
      "\n",
      "    accuracy                         0.6522      1107\n",
      "   macro avg     0.6534    0.6585    0.6548      1107\n",
      "weighted avg     0.6528    0.6522    0.6516      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Accuracy:  0.6349621265953467\n",
      "F1 Macro:  0.6400360917802084\n",
      "Precision Macro:  0.6426631327242804\n",
      "Recall Macro:  0.645384910973032\n"
     ]
    }
   ],
   "source": [
    "! python3 -m speech_models.speech_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.6909    0.3654    0.4780       208\n",
      "         hap     0.4753    0.4858    0.4805       317\n",
      "         neu     0.4264    0.3848    0.4046       369\n",
      "         sad     0.4118    0.6573    0.5063       213\n",
      "\n",
      "    accuracy                         0.4625      1107\n",
      "   macro avg     0.5011    0.4733    0.4673      1107\n",
      "weighted avg     0.4873    0.4625    0.4597      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "Accuracy:  0.4671823722456634\n",
      "F1 Macro:  0.46394380739887814\n",
      "Precision Macro:  0.4987730153799331\n",
      "Recall Macro:  0.46867978719268166\n"
     ]
    }
   ],
   "source": [
    "! python3 -m speech_models.speech_naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.7557    0.6394    0.6927       208\n",
      "         hap     0.6087    0.5741    0.5909       317\n",
      "         neu     0.6019    0.6721    0.6351       369\n",
      "         sad     0.6364    0.6573    0.6467       213\n",
      "\n",
      "    accuracy                         0.6350      1107\n",
      "   macro avg     0.6507    0.6357    0.6413      1107\n",
      "weighted avg     0.6394    0.6350    0.6355      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "Accuracy:  0.6168825377223032\n",
      "F1 Macro:  0.6228951152108857\n",
      "Precision Macro:  0.6400016121146235\n",
      "Recall Macro:  0.6149222821421991\n"
     ]
    }
   ],
   "source": [
    "! python3 -m speech_models.speech_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.6204    0.7308    0.6711       208\n",
      "         hap     0.6678    0.6088    0.6370       317\n",
      "         neu     0.7043    0.6260    0.6628       369\n",
      "         sad     0.6612    0.7606    0.7074       213\n",
      "\n",
      "    accuracy                         0.6667      1107\n",
      "   macro avg     0.6634    0.6815    0.6696      1107\n",
      "weighted avg     0.6698    0.6667    0.6656      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "Accuracy:  0.6638901548750267\n",
      "F1 Macro:  0.6697158368856151\n",
      "Precision Macro:  0.6676657458843194\n",
      "Recall Macro:  0.6725616598809877\n"
     ]
    }
   ],
   "source": [
    "! python3 -m speech_models.speech_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "On Train/Test Split\n",
      "\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[06:28:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.6857    0.6923    0.6890       208\n",
      "         hap     0.6678    0.6151    0.6404       317\n",
      "         neu     0.6882    0.6640    0.6759       369\n",
      "         sad     0.6747    0.7887    0.7273       213\n",
      "\n",
      "    accuracy                         0.6793      1107\n",
      "   macro avg     0.6791    0.6900    0.6831      1107\n",
      "weighted avg     0.6793    0.6793    0.6781      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[06:29:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:29:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:29:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:29:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:29:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy:  0.6785365526952437\n",
      "F1 Macro:  0.6859354923540206\n",
      "Precision Macro:  0.6908742518950945\n",
      "Recall Macro:  0.6840054203247408\n"
     ]
    }
   ],
   "source": [
    "! python3 -m speech_models.speech_xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.7778    0.6731    0.7216       208\n",
      "         hap     0.6959    0.6498    0.6721       317\n",
      "         neu     0.5963    0.7046    0.6460       369\n",
      "         sad     0.6462    0.5915    0.6176       213\n",
      "\n",
      "    accuracy                         0.6612      1107\n",
      "   macro avg     0.6791    0.6548    0.6643      1107\n",
      "weighted avg     0.6685    0.6612    0.6622      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "Accuracy:  0.6613642266621582\n",
      "F1 Macro:  0.6623508565649627\n",
      "Precision Macro:  0.6814603656075838\n",
      "Recall Macro:  0.6519552646088471\n"
     ]
    }
   ],
   "source": [
    "! python3 -m text_models.text_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.7684    0.7019    0.7337       208\n",
      "         hap     0.6526    0.6814    0.6667       317\n",
      "         neu     0.6277    0.6396    0.6336       369\n",
      "         sad     0.6333    0.6244    0.6288       213\n",
      "\n",
      "    accuracy                         0.6603      1107\n",
      "   macro avg     0.6705    0.6618    0.6657      1107\n",
      "weighted avg     0.6623    0.6603    0.6609      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "Accuracy:  0.6559381283987644\n",
      "F1 Macro:  0.658711231476486\n",
      "Precision Macro:  0.669414684581496\n",
      "Recall Macro:  0.6521219342334894\n"
     ]
    }
   ],
   "source": [
    "! python3 -m text_models.text_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.7312    0.6538    0.6904       208\n",
      "         hap     0.6109    0.5994    0.6051       317\n",
      "         neu     0.5601    0.6314    0.5936       369\n",
      "         sad     0.5928    0.5399    0.5651       213\n",
      "\n",
      "    accuracy                         0.6089      1107\n",
      "   macro avg     0.6237    0.6061    0.6135      1107\n",
      "weighted avg     0.6131    0.6089    0.6096      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "Accuracy:  0.645813506356884\n",
      "F1 Macro:  0.6463176522593687\n",
      "Precision Macro:  0.6625101207606496\n",
      "Recall Macro:  0.6376181370200869\n"
     ]
    }
   ],
   "source": [
    "! python3 -m text_models.text_naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8144    0.6538    0.7253       208\n",
      "         hap     0.6677    0.6656    0.6667       317\n",
      "         neu     0.5738    0.6640    0.6156       369\n",
      "         sad     0.6193    0.5728    0.5951       213\n",
      "\n",
      "    accuracy                         0.6450      1107\n",
      "   macro avg     0.6688    0.6390    0.6507      1107\n",
      "weighted avg     0.6546    0.6450    0.6469      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "Accuracy:  0.6441878168028213\n",
      "F1 Macro:  0.6474491657988038\n",
      "Precision Macro:  0.6712553291149568\n",
      "Recall Macro:  0.6350092301636605\n"
     ]
    }
   ],
   "source": [
    "! python3 -m text_models.text_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Train/Test Split\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.8322    0.5962    0.6947       208\n",
      "         hap     0.6796    0.6625    0.6709       317\n",
      "         neu     0.5644    0.7480    0.6434       369\n",
      "         sad     0.6562    0.4930    0.5630       213\n",
      "\n",
      "    accuracy                         0.6459      1107\n",
      "   macro avg     0.6831    0.6249    0.6430      1107\n",
      "weighted avg     0.6654    0.6459    0.6454      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "Accuracy:  0.6423788451266068\n",
      "F1 Macro:  0.6428044822540336\n",
      "Precision Macro:  0.6855739502744447\n",
      "Recall Macro:  0.6260786644152045\n"
     ]
    }
   ],
   "source": [
    "! python3 -m text_models.text_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "On Train/Test Split\n",
      "\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[06:40:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.7557    0.6394    0.6927       208\n",
      "         hap     0.6801    0.6372    0.6580       317\n",
      "         neu     0.5829    0.6856    0.6301       369\n",
      "         sad     0.5900    0.5540    0.5714       213\n",
      "\n",
      "    accuracy                         0.6378      1107\n",
      "   macro avg     0.6522    0.6291    0.6381      1107\n",
      "weighted avg     0.6446    0.6378    0.6386      1107\n",
      "\n",
      "On K-fold Cross Validation\n",
      "\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/rafid/Documents/github/emotion-recognition-ensemble-learning/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[06:40:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:40:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:40:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:40:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:40:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy:  0.6445478469251239\n",
      "F1 Macro:  0.6469443298212532\n",
      "Precision Macro:  0.6667118107410428\n",
      "Recall Macro:  0.6362928928873026\n"
     ]
    }
   ],
   "source": [
    "! python3 -m text_models.text_xgboost"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43977b93b591f9c5f764aaf55cf98677b19fb5109c886483ea86b303d412ecc0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
