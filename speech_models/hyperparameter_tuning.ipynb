{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from process_dataset import speech_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test():\n",
    "    with open('../data/speech_features.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    x = np.array(data[0])\n",
    "    y = np.array(data[1])\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def get_x_y():\n",
    "    x_train, x_test, y_train, y_test = get_train_test()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "def check_accuracy(model):\n",
    "    x_train, x_test, y_train, y_test = get_train_test()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    results = model.predict(x_test)\n",
    "\n",
    "    print(classification_report(y_test, results, digits=4))\n",
    "\n",
    "\n",
    "x, y = get_x_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.6603    0.6635    0.6619       208\n",
      "         hap     0.6117    0.5962    0.6038       317\n",
      "         neu     0.6727    0.6070    0.6382       369\n",
      "         sad     0.6094    0.7324    0.6652       213\n",
      "\n",
      "    accuracy                         0.6387      1107\n",
      "   macro avg     0.6385    0.6498    0.6423      1107\n",
      "weighted avg     0.6407    0.6387    0.6380      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "# lr = LogisticRegression(C=0.6, class_weight='balanced', random_state=42, solver='liblinear')\n",
    "\n",
    "check_accuracy(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'solver': ['liblinear', 'saga', 'sag'],\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : [0.01, 0.1, 0.6, 1, 10, 30],\n",
    "    'fit_intercept': [True, False],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'max_iter': [2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_g = RandomizedSearchCV(LogisticRegression(random_state=42), param_distributions=params, n_iter=50, n_jobs=-1, cv=5, random_state=42, verbose=5)\n",
    "\n",
    "lr_g.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'saga', 'penalty': 'l1', 'multi_class': 'auto', 'max_iter': 2000, 'fit_intercept': True, 'class_weight': None, 'C': 0.6}\n",
      "0.636981874888156\n",
      "LogisticRegression(C=0.6, max_iter=2000, penalty='l1', random_state=42,\n",
      "                   solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(lr_g.best_params_)\n",
    "print(lr_g.best_score_)\n",
    "print(lr_g.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 combinations per fold\n"
     ]
    }
   ],
   "source": [
    "params1 = {\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'solver' : ['liblinear', 'saga'],\n",
    "    'C': [0.5, 0.7, 0.6],\n",
    "    'max_iter': [2000]\n",
    "}\n",
    "lr_g1 = GridSearchCV(LogisticRegression(random_state=42), param_grid=params1, cv=5, return_train_score=False, verbose=5, n_jobs=-1)\n",
    "\n",
    "pg = ParameterGrid(params1)\n",
    "print(len(pg), 'combinations per fold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_g1.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636981874888156\n",
      "{'C': 0.6, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "LogisticRegression(C=0.6, max_iter=2000, penalty='l1', random_state=42,\n",
      "                   solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(lr_g1.best_score_)\n",
    "print(lr_g1.best_params_)\n",
    "print(lr_g1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.6618    0.6490    0.6553       208\n",
      "         hap     0.5981    0.5868    0.5924       317\n",
      "         neu     0.6706    0.6233    0.6461       369\n",
      "         sad     0.6305    0.7371    0.6797       213\n",
      "\n",
      "    accuracy                         0.6396      1107\n",
      "   macro avg     0.6402    0.6490    0.6434      1107\n",
      "weighted avg     0.6404    0.6396    0.6389      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1, max_iter=2000, penalty='l1', random_state=42, solver='saga')\n",
    "check_accuracy(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang       0.64      0.66      0.65       208\n",
      "         hap       0.59      0.57      0.58       317\n",
      "         neu       0.70      0.62      0.65       369\n",
      "         sad       0.62      0.75      0.68       213\n",
      "\n",
      "    accuracy                           0.64      1107\n",
      "   macro avg       0.64      0.65      0.64      1107\n",
      "weighted avg       0.64      0.64      0.64      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm = SVC(random_state=42)\n",
    "# svm = SVC(C=0.5, decision_function_shape='ovo', degree=5, kernel='linear', probability=True, random_state=42)\n",
    "svm = SVC(C=0.5, decision_function_shape='ovo', degree=5, kernel='linear', probability=True, random_state=42)\n",
    "check_accuracy(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'C': [0.01, 0.1, 0.5, 1, 5, 10, 20],\n",
    "    'kernel' : ['linear'],\n",
    "    'degree': [1, 3, 5, 7],\n",
    "    'shrinking': [True, False],\n",
    "    'probability': [True],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_g = RandomizedSearchCV(SVC(random_state=42), param_distributions=params, n_iter=25, n_jobs=-1, cv=3, random_state=42, verbose=5)\n",
    "\n",
    "svm_g.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shrinking': True, 'probability': True, 'kernel': 'linear', 'degree': 5, 'decision_function_shape': 'ovo', 'class_weight': None, 'C': 0.5}\n",
      "0.6228514490152298\n",
      "SVC(C=0.5, decision_function_shape='ovo', degree=5, kernel='linear',\n",
      "    probability=True, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(svm_g.best_params_)\n",
    "print(svm_g.best_score_)\n",
    "print(svm_g.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 combinations per fold\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [0.5, 0.75, 0.85],\n",
    "    'kernel' : ['linear'],\n",
    "    'degree': [5, 6, 7],\n",
    "    'probability': [True],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "}\n",
    "svm_g = GridSearchCV(SVC(random_state=42), param_grid=params, cv=3, return_train_score=False, verbose=5, n_jobs=-1)\n",
    "\n",
    "pg = ParameterGrid(params)\n",
    "print(len(pg), 'combinations per fold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_g.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shrinking': True, 'probability': True, 'kernel': 'linear', 'degree': 5, 'decision_function_shape': 'ovo', 'class_weight': None, 'C': 0.5}\n",
      "0.6228514490152298\n",
      "SVC(C=0.5, decision_function_shape='ovo', degree=5, kernel='linear',\n",
      "    probability=True, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(svm_g.best_params_)\n",
    "print(svm_g.best_score_)\n",
    "print(svm_g.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.7195    0.5673    0.6344       208\n",
      "         hap     0.5855    0.5615    0.5733       317\n",
      "         neu     0.5829    0.6477    0.6136       369\n",
      "         sad     0.6114    0.6573    0.6335       213\n",
      "\n",
      "    accuracy                         0.6098      1107\n",
      "   macro avg     0.6248    0.6084    0.6137      1107\n",
      "weighted avg     0.6148    0.6098    0.6098      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "# rf = RandomForestClassifier(bootstrap=False, criterion='gini', max_depth=20, max_features=0.3, min_samples_split=10, n_estimators=150, random_state=42, n_jobs=-1)\n",
    "check_accuracy(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [10, 50, 85, 100, 150, 200, 500, 1000, 1500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 120, num = 12)],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.2,],\n",
    "    'min_samples_leaf': [1, 3, 5, 8, 12],\n",
    "    'min_samples_split' : [2, 6, 10, 15, 20]\n",
    "}\n",
    "\n",
    "rf_g = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_distributions=params, n_iter=50, n_jobs=-1, cv=5, random_state=42, verbose=5)\n",
    "\n",
    "rf_g.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 0.2, 'max_depth': 120, 'criterion': 'entropy', 'bootstrap': False}\n",
      "0.6200273538359281\n",
      "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=120,\n",
      "                       max_features=0.2, min_samples_split=10,\n",
      "                       n_estimators=1500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(rf_g.best_params_)\n",
    "print(rf_g.best_score_)\n",
    "print(rf_g.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 combinations per fold\n"
     ]
    }
   ],
   "source": [
    "params1 = {\n",
    "    'n_estimators': [1500, 150, 200],\n",
    "    'min_samples_split': [10],\n",
    "    'min_samples_leaf': [1, 5],\n",
    "    'max_features': [0.2, 0.3],\n",
    "    'max_depth': [120, 500],\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'bootstrap': [False],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "rf_g1 = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=params1, cv=5, return_train_score=False, verbose=5, n_jobs=-1)\n",
    "\n",
    "pg = ParameterGrid(params1)\n",
    "print(len(pg), 'combinations per fold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_g1.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6209307973515352\n",
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': 120, 'max_features': 0.3, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1500, 'n_jobs': -1}\n",
      "RandomForestClassifier(bootstrap=False, max_depth=120, max_features=0.3,\n",
      "                       min_samples_split=10, n_estimators=1500, n_jobs=-1,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(rf_g1.best_score_)\n",
    "print(rf_g1.best_params_)\n",
    "print(rf_g1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.7557    0.6394    0.6927       208\n",
      "         hap     0.6087    0.5741    0.5909       317\n",
      "         neu     0.6019    0.6721    0.6351       369\n",
      "         sad     0.6364    0.6573    0.6467       213\n",
      "\n",
      "    accuracy                         0.6350      1107\n",
      "   macro avg     0.6507    0.6357    0.6413      1107\n",
      "weighted avg     0.6394    0.6350    0.6355      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=False, max_depth=120, max_features=0.3,\n",
    "                       min_samples_split=10, n_estimators=1500, n_jobs=-1,\n",
    "                       random_state=42)\n",
    "check_accuracy(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafid/Documents/github/CSE400-NLP/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:23:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.7108    0.6971    0.7039       208\n",
      "         hap     0.6560    0.5836    0.6177       317\n",
      "         neu     0.6684    0.6883    0.6782       369\n",
      "         sad     0.6763    0.7653    0.7181       213\n",
      "\n",
      "    accuracy                         0.6748      1107\n",
      "   macro avg     0.6779    0.6836    0.6795      1107\n",
      "weighted avg     0.6744    0.6748    0.6734      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=42, tree_method='gpu_hist')\n",
    "check_accuracy(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    \"learning_rate\"    : [0.05, 0.10, 0.20, 0.30] ,\n",
    "    \"max_depth\"        : [ 1, 3, 5, 8],\n",
    "    \"min_child_weight\" : [ 1, 3, 5 ],\n",
    "    \"gamma\"            : [ 0.0, 0.1, 0.5 , 1.5, 3 ],\n",
    "    \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7, 1 ],\n",
    "    \"subsample\": [0.5, 0.75, 1],\n",
    "    \"reg_lambda\": [0.2, 0.5, 0.8],\n",
    "    \"n_estimators\": [100, 500, 750, 1000]\n",
    "}\n",
    "\n",
    "xgb_g = RandomizedSearchCV(XGBClassifier(random_state=42, tree_method='gpu_hist'), param_distributions=params, n_iter=70, n_jobs=-1, cv=5, random_state=42, verbose=5)\n",
    "\n",
    "xgb_g.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.75, 'reg_lambda': 0.8, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.05, 'gamma': 0.5, 'colsample_bytree': 1}\n",
      "0.667267172840453\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0.5, gpu_id=0, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=1000, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=42, reg_alpha=0, reg_lambda=0.8,\n",
      "              scale_pos_weight=None, subsample=0.75, tree_method='gpu_hist',\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(xgb_g.best_params_)\n",
    "print(xgb_g.best_score_)\n",
    "print(xgb_g.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 combinations per fold\n"
     ]
    }
   ],
   "source": [
    "params1 = {\n",
    "    \"learning_rate\"    : [0.05, 0.02, 0.07] ,\n",
    "    \"max_depth\"        : [3, 7],\n",
    "    \"gamma\"            : [ 0.3, 0.5],\n",
    "    \"subsample\": [0.6, 0.75, 0.9],\n",
    "    \"reg_lambda\": [0.8],\n",
    "    \"n_estimators\": [1000, 1500]\n",
    "}\n",
    "\n",
    "xgb_g1 = GridSearchCV(XGBClassifier(random_state=42, tree_method='gpu_hist'), param_grid=params1, cv=5, return_train_score=False, verbose=5, n_jobs=-1)\n",
    "\n",
    "pg = ParameterGrid(params1)\n",
    "print(len(pg), 'combinations per fold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_g1.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6699813380371705\n",
      "{'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 1500, 'reg_lambda': 0.8, 'subsample': 0.75}\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0.5, gpu_id=0, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=1500, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=42, reg_alpha=0, reg_lambda=0.8,\n",
      "              scale_pos_weight=None, subsample=0.75, tree_method='gpu_hist',\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(xgb_g1.best_score_)\n",
    "print(xgb_g1.best_params_)\n",
    "print(xgb_g1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafid/Documents/github/CSE400-NLP/env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:22:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ang     0.6857    0.6923    0.6890       208\n",
      "         hap     0.6678    0.6151    0.6404       317\n",
      "         neu     0.6882    0.6640    0.6759       369\n",
      "         sad     0.6747    0.7887    0.7273       213\n",
      "\n",
      "    accuracy                         0.6793      1107\n",
      "   macro avg     0.6791    0.6900    0.6831      1107\n",
      "weighted avg     0.6793    0.6793    0.6781      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "              gamma=0.5, gpu_id=0, importance_type=None,\n",
    "              interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
    "              max_depth=3, min_child_weight=1,\n",
    "              monotone_constraints='()', n_estimators=1500, n_jobs=8,\n",
    "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
    "              random_state=42, reg_alpha=0, reg_lambda=0.8,\n",
    "              scale_pos_weight=None, subsample=0.75, tree_method='gpu_hist',\n",
    "              validate_parameters=1, verbosity=None)\n",
    "check_accuracy(xgb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ed4bbf83b94bed540e4a6248a5de1e2eb8a809c16f0f6392d7883b316929957"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
